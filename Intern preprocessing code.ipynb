{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cb91330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 530 unique words in the file\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "# Function to remove stopwords, pronouns, and tense words\n",
    "def remove_stopwords(words):\n",
    "    # Define Hindi stopwords (conjunctions and postpositions)\n",
    "    stopwords = [\"और\", \"के\", \"से\", \"का\", \"की\", \"को\", \"है\", \"हैं\", \"की\",\n",
    "                 \"या\", \"में\", \"पर\", \"एक\", \"होता\", \"है।\", \"रहे\", \"तक\", \"कि\"]\n",
    "    # Define Hindi pronouns\n",
    "    pronouns = [\"मैं\", \"मुझे\", \"मुझ\", \"मुझको\", \"मुझें\", \"तुम\", \"तुम्हे\", \"तुझ\", \"तुझको\", \"तुझें\", \"वह\", \"उसे\", \"उस\", \"उसको\", \"उसेँ\", \"यह\", \"इसे\", \"इस\", \"इसको\", \"इसेँ\", \"हम\", \"हमें\", \"हमें\", \"आप\", \"आपको\", \"आपको\", \"आपस\", \"ये\", \"इनको\", \"इन\", \"इनको\", \"इनें\", \"वो\", \"उनको\", \"उन्हें\", \"उन्हें\", \"उन्हें\", \"कौन\", \"किसे\", \"किस\", \"किसको\", \"किसेँ\", \"क्या\", \" किसका\", \"किसकी\", \"किसके\", \"किसको\", \"किससे\"]\n",
    "    # Define Hindi tense words\n",
    "    tense_words = [\"रहा\", \"रही\", \"रहे\", \"जा\", \"जाना\", \"आ\", \"आया\", \"आई\", \"आये\", \"गया\", \"गई\", \"गए\",\n",
    "                   \"किया\", \"किये\", \"हो\", \"होगा\", \"होगी\", \"होंगे\", \"हुआ\", \"हुई\", \"हुए\"]\n",
    "    \n",
    "    # Combine all words to be removed\n",
    "    words_to_remove = stopwords + pronouns + tense_words\n",
    "    \n",
    "    filtered_words = [word for word in words if word not in words_to_remove]\n",
    "    return filtered_words\n",
    "\n",
    "lines = [] #list of all lines\n",
    "words = [] #list of all words\n",
    "\n",
    "f = open('news100.txt', 'r', encoding='utf8') #open the text file \n",
    "for line in f:           #read from text line by line\n",
    "    lines.append(line)   #save lines one by one\n",
    "f.close()                #close the text file\n",
    "\n",
    "for line in lines:      #will go through the list line by line\n",
    "    wds = line.split()  #break each line into words\n",
    "    words += wds        #add all words to the list called words\n",
    "\n",
    "# Remove stopwords, pronouns, and tense words\n",
    "words = remove_stopwords(words)\n",
    "\n",
    "count = 0               #count for current word\n",
    "while count < len(words): \n",
    "    word = words[count]   # defining word from words by count\n",
    "    if any(l.isnumeric() for l in word):  #check if digit in the word\n",
    "        words.pop(count)  #if so delete that string/word from the list\n",
    "    else:\n",
    "         #we can check the result by \"print(count, words[count])\" \n",
    "        count += 1   #if not add 1 to it\n",
    "\n",
    "# Count frequency of each word\n",
    "word_frequency = {}\n",
    "for word in words:\n",
    "    word_frequency[word] = word_frequency.get(word, 0) + 1\n",
    "\n",
    "output_file = open('news_output.txt', 'w', encoding='utf-8')  # open output file\n",
    "\n",
    "# Write unique words and their frequencies to output file\n",
    "for word, frequency in word_frequency.items():\n",
    "    output_file.write(f\"{word}: {frequency}\\n\")\n",
    "\n",
    "output_file.close() # Close output file\n",
    "print('there are', len(word_frequency), 'unique words in the file') #print total number of unique words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b13f446",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
